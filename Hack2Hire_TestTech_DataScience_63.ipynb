{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        1000 non-null   int64 \n",
      " 1   Age               1000 non-null   int64 \n",
      " 2   Sex               1000 non-null   object\n",
      " 3   Job               1000 non-null   int64 \n",
      " 4   Housing           1000 non-null   object\n",
      " 5   Saving accounts   817 non-null    object\n",
      " 6   Checking account  606 non-null    object\n",
      " 7   Credit amount     1000 non-null   int64 \n",
      " 8   Duration          1000 non-null   int64 \n",
      " 9   Purpose           1000 non-null   object\n",
      " 10  Risk              1000 non-null   object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 86.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'head':    Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
       " 0           0   67    male    2     own             NaN           little   \n",
       " 1           1   22  female    2     own          little         moderate   \n",
       " 2           2   49    male    1     own          little              NaN   \n",
       " 3           3   45    male    2    free          little           little   \n",
       " 4           4   53    male    2    free          little           little   \n",
       " \n",
       "    Credit amount  Duration              Purpose  Risk  \n",
       " 0           1169         6             radio/TV  good  \n",
       " 1           5951        48             radio/TV   bad  \n",
       " 2           2096        12            education  good  \n",
       " 3           7882        42  furniture/equipment  good  \n",
       " 4           4870        24                  car   bad  ,\n",
       " 'info': None,\n",
       " 'description':                    count unique     top freq      mean          std    min  \\\n",
       " Unnamed: 0        1000.0    NaN     NaN  NaN     499.5   288.819436    0.0   \n",
       " Age               1000.0    NaN     NaN  NaN    35.546    11.375469   19.0   \n",
       " Sex                 1000      2    male  690       NaN          NaN    NaN   \n",
       " Job               1000.0    NaN     NaN  NaN     1.904     0.653614    0.0   \n",
       " Housing             1000      3     own  713       NaN          NaN    NaN   \n",
       " Saving accounts      817      4  little  603       NaN          NaN    NaN   \n",
       " Checking account     606      3  little  274       NaN          NaN    NaN   \n",
       " Credit amount     1000.0    NaN     NaN  NaN  3271.258  2822.736876  250.0   \n",
       " Duration          1000.0    NaN     NaN  NaN    20.903    12.058814    4.0   \n",
       " Purpose             1000      8     car  337       NaN          NaN    NaN   \n",
       " Risk                1000      2    good  700       NaN          NaN    NaN   \n",
       " \n",
       "                      25%     50%      75%      max  \n",
       " Unnamed: 0        249.75   499.5   749.25    999.0  \n",
       " Age                 27.0    33.0     42.0     75.0  \n",
       " Sex                  NaN     NaN      NaN      NaN  \n",
       " Job                  2.0     2.0      2.0      3.0  \n",
       " Housing              NaN     NaN      NaN      NaN  \n",
       " Saving accounts      NaN     NaN      NaN      NaN  \n",
       " Checking account     NaN     NaN      NaN      NaN  \n",
       " Credit amount     1365.5  2319.5  3972.25  18424.0  \n",
       " Duration            12.0    18.0     24.0     72.0  \n",
       " Purpose              NaN     NaN      NaN      NaN  \n",
       " Risk                 NaN     NaN      NaN      NaN  }"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file uploaded by the user\n",
    "csv_file_path = '/home/aimssn-it/Desktop/Databeez/german_credit_data.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows and basic information about the dataset\n",
    "data_info = {\n",
    "    \"head\": data.head(),\n",
    "    \"info\": data.info(),\n",
    "    \"description\": data.describe(include='all').T,\n",
    "}\n",
    "\n",
    "data_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c1885b1e764d648669effa13c0899c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773d35f2a40d423d8756148737dc9921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baf43080a6740798ef5e34de0587a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854c5f02f9f84c6fadd5750b5d820c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a profiling report\n",
    "profile = ProfileReport(data, title=\"Credit Risk Germany Data Profiling Report\", explorative=True)\n",
    "\n",
    "# Display the profiling report\n",
    "profile.to_file(\"credit_risk_germany_data_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Age and Duration are left skewed, we are going to make them normally distributed with:\n",
    "- data['Age']= np.log1p(data['Age']) or \n",
    "- data['Age'] = np.sqrt(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Age'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = np.log1p(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Age'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Credit amount'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Credit amount'] = np.log1p(data['Credit amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Credit amount'], kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_types': Age                 float64\n",
       " Sex                  object\n",
       " Job                   int64\n",
       " Housing              object\n",
       " Saving accounts      object\n",
       " Checking account     object\n",
       " Credit amount       float64\n",
       " Duration              int64\n",
       " Purpose              object\n",
       " Risk                 object\n",
       " dtype: object,\n",
       " 'missing_values': Age                   0\n",
       " Sex                   0\n",
       " Job                   0\n",
       " Housing               0\n",
       " Saving accounts     183\n",
       " Checking account    394\n",
       " Credit amount         0\n",
       " Duration              0\n",
       " Purpose               0\n",
       " Risk                  0\n",
       " dtype: int64,\n",
       " 'summary_statistics':                 Age   Sex          Job Housing Saving accounts  \\\n",
       " count   1000.000000  1000  1000.000000    1000             817   \n",
       " unique          NaN     2          NaN       3               4   \n",
       " top             NaN  male          NaN     own          little   \n",
       " freq            NaN   690          NaN     713             603   \n",
       " mean       3.554569   NaN     1.904000     NaN             NaN   \n",
       " std        0.291418   NaN     0.653614     NaN             NaN   \n",
       " min        2.995732   NaN     0.000000     NaN             NaN   \n",
       " 25%        3.332205   NaN     2.000000     NaN             NaN   \n",
       " 50%        3.526361   NaN     2.000000     NaN             NaN   \n",
       " 75%        3.761200   NaN     2.000000     NaN             NaN   \n",
       " max        4.330733   NaN     3.000000     NaN             NaN   \n",
       " \n",
       "        Checking account  Credit amount     Duration Purpose  Risk  \n",
       " count               606    1000.000000  1000.000000    1000  1000  \n",
       " unique                3            NaN          NaN       8     2  \n",
       " top              little            NaN          NaN     car  good  \n",
       " freq                274            NaN          NaN     337   700  \n",
       " mean                NaN       7.789244    20.903000     NaN   NaN  \n",
       " std                 NaN       0.776074    12.058814     NaN   NaN  \n",
       " min                 NaN       5.525453     4.000000     NaN   NaN  \n",
       " 25%                 NaN       7.220008    12.000000     NaN   NaN  \n",
       " 50%                 NaN       7.749538    18.000000     NaN   NaN  \n",
       " 75%                 NaN       8.287340    24.000000     NaN   NaN  \n",
       " max                 NaN       9.821464    72.000000     NaN   NaN  }"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types of each column\n",
    "data_types = data.dtypes\n",
    "\n",
    "# Count of missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Summary statistics\n",
    "summary_statistics = data.describe(include='all')\n",
    "\n",
    "data_analysis = {\n",
    "    \"data_types\": data_types,\n",
    "    \"missing_values\": missing_values,\n",
    "    \"summary_statistics\": summary_statistics\n",
    "}\n",
    "\n",
    "data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.219508</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>7.064759</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.135494</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>8.691483</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.912023</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.648263</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.828641</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>8.972464</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.988984</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>8.491055</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age     Sex  Job Housing Saving accounts Checking account  \\\n",
       "0  4.219508    male    2     own             NaN           little   \n",
       "1  3.135494  female    2     own          little         moderate   \n",
       "2  3.912023    male    1     own          little              NaN   \n",
       "3  3.828641    male    2    free          little           little   \n",
       "4  3.988984    male    2    free          little           little   \n",
       "\n",
       "   Credit amount  Duration              Purpose  Risk  \n",
       "0       7.064759         6             radio/TV  good  \n",
       "1       8.691483        48             radio/TV   bad  \n",
       "2       7.648263        12            education  good  \n",
       "3       8.972464        42  furniture/equipment  good  \n",
       "4       8.491055        24                  car   bad  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values\n",
    "data = data.assign(**{\n",
    "    'Saving accounts': data['Saving accounts'].fillna('unknown'),\n",
    "    'Checking account': data['Checking account'].fillna('unknown')\n",
    "})\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = data.copy()\n",
    "data_encoded['Sex'] = data_encoded['Sex'].map({'male': 0, 'female': 1})\n",
    "data_encoded['Housing'] = data_encoded['Housing'].map({'own': 0, 'rent': 1, 'free': 2})\n",
    "data_encoded['Saving accounts'] = data_encoded['Saving accounts'].astype('category').cat.codes\n",
    "data_encoded['Checking account'] = data_encoded['Checking account'].astype('category').cat.codes\n",
    "data_encoded['Purpose'] = data_encoded['Purpose'].astype('category').cat.codes\n",
    "data_encoded['Risk'] = data_encoded['Risk'].map({'good': 1, 'bad': 0})\n",
    "\n",
    "# Normalize or scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Age', 'Job', 'Credit amount', 'Duration']\n",
    "data_encoded[numerical_features] = scaler.fit_transform(data_encoded[numerical_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account',\n",
       "       'Credit amount', 'Duration', 'Purpose', 'Risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.282879</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146949</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.933992</td>\n",
       "      <td>-1.236478</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.438777</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.163149</td>\n",
       "      <td>2.248194</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.227217</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.383771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.181750</td>\n",
       "      <td>-0.738668</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.940950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146949</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.525385</td>\n",
       "      <td>1.750384</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.491441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146949</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904761</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Sex       Job  Housing  Saving accounts  Checking account  \\\n",
       "0  2.282879    0  0.146949        0                4                 0   \n",
       "1 -1.438777    1  0.146949        0                0                 1   \n",
       "2  1.227217    0 -1.383771        0                0                 3   \n",
       "3  0.940950    0  0.146949        2                0                 0   \n",
       "4  1.491441    0  0.146949        2                0                 0   \n",
       "\n",
       "   Credit amount  Duration  Purpose  Risk  \n",
       "0      -0.933992 -1.236478        5     1  \n",
       "1       1.163149  2.248194        5     0  \n",
       "2      -0.181750 -0.738668        3     1  \n",
       "3       1.525385  1.750384        4     1  \n",
       "4       0.904761  0.256953        1     0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d397ae9f364e348bf81703fff68bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c99820c4cf4fc68ce0ffa457511d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bfa8c32a7a4c3fbe4050b30c0a47b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e7f241507b4884b172673f8169f2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a profiling report\n",
    "profile = ProfileReport(data_encoded, title=\"Credit Risk Germany Data Profiling Report\", explorative=True)\n",
    "\n",
    "# Display the profiling report\n",
    "profile.to_file(\"preprocessed_credit_risk_germany_data_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Age       Sex       Job   Housing  Saving accounts  \\\n",
      "Age               1.000000 -0.194999  0.028823  0.093109         0.092608   \n",
      "Sex              -0.194999  1.000000 -0.070298  0.033818        -0.034982   \n",
      "Job               0.028823 -0.070298  1.000000  0.101939         0.011709   \n",
      "Housing           0.093109  0.033818  0.101939  1.000000        -0.003262   \n",
      "Saving accounts   0.092608 -0.034982  0.011709 -0.003262         1.000000   \n",
      "Checking account  0.077562 -0.025578  0.040663 -0.121380         0.222867   \n",
      "Credit amount     0.023974 -0.116756  0.304628  0.163745         0.064227   \n",
      "Duration         -0.027167 -0.081432  0.210910  0.137434         0.047661   \n",
      "Purpose          -0.083564  0.063231 -0.025326 -0.086839        -0.053225   \n",
      "Risk              0.102463 -0.075493 -0.032735 -0.127789         0.178943   \n",
      "\n",
      "                  Checking account  Credit amount  Duration   Purpose  \\\n",
      "Age                       0.077562       0.023974 -0.027167 -0.083564   \n",
      "Sex                      -0.025578      -0.116756 -0.081432  0.063231   \n",
      "Job                       0.040663       0.304628  0.210910 -0.025326   \n",
      "Housing                  -0.121380       0.163745  0.137434 -0.086839   \n",
      "Saving accounts           0.222867       0.064227  0.047661 -0.053225   \n",
      "Checking account          1.000000      -0.022033 -0.072013  0.016253   \n",
      "Credit amount            -0.022033       1.000000  0.640850 -0.157467   \n",
      "Duration                 -0.072013       0.640850  1.000000 -0.083459   \n",
      "Purpose                   0.016253      -0.157467 -0.083459  1.000000   \n",
      "Risk                      0.350847      -0.109588 -0.214927  0.061145   \n",
      "\n",
      "                      Risk  \n",
      "Age               0.102463  \n",
      "Sex              -0.075493  \n",
      "Job              -0.032735  \n",
      "Housing          -0.127789  \n",
      "Saving accounts   0.178943  \n",
      "Checking account  0.350847  \n",
      "Credit amount    -0.109588  \n",
      "Duration         -0.214927  \n",
      "Purpose           0.061145  \n",
      "Risk              1.000000  \n",
      "Correlation with target variable 'Risk':\n",
      "Risk                1.000000\n",
      "Checking account    0.350847\n",
      "Saving accounts     0.178943\n",
      "Age                 0.102463\n",
      "Purpose             0.061145\n",
      "Job                -0.032735\n",
      "Sex                -0.075493\n",
      "Credit amount      -0.109588\n",
      "Housing            -0.127789\n",
      "Duration           -0.214927\n",
      "Name: Risk, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = data_encoded.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Check correlation with the target variable 'Risk'\n",
    "correlation_with_target = correlation_matrix['Risk'].sort_values(ascending=False)\n",
    "print(\"Correlation with target variable 'Risk':\")\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify key variables influencing credit scoring using correlation matrices and visualizations (e.g., heatmaps, pair plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pair plot for selected features\n",
    "selected_features = ['Age', 'Job', 'Credit amount', 'Duration', 'Saving accounts','Purpose','Checking account','Risk']\n",
    "sns.pairplot(data_encoded[selected_features], hue='Risk', palette='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./databeezhackvenv/lib/python3.12/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./databeezhackvenv/lib/python3.12/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./databeezhackvenv/lib/python3.12/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./databeezhackvenv/lib/python3.12/site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./databeezhackvenv/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./databeezhackvenv/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk\n",
      "1    700\n",
      "0    700\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data_encoded.drop('Risk', axis=1)\n",
    "y = data_encoded['Risk']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Update data_encoded with the resampled data\n",
    "data_encoded = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=['Risk'])], axis=1)\n",
    "\n",
    "# Verify the balance of the target variable\n",
    "print(data_encoded['Risk'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = data_encoded.drop('Risk', axis=1)\n",
    "y = data_encoded['Risk']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7771\n",
      "Recall: 0.9149\n",
      "F1-score: 0.8404\n",
      "AUC-ROC: 0.6439\n",
      "[[ 22  37]\n",
      " [ 12 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47        59\n",
      "           1       0.78      0.91      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.64      0.66       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7875\n",
      "Recall: 0.8936\n",
      "F1-score: 0.8372\n",
      "AUC-ROC: 0.6587\n",
      "[[ 25  34]\n",
      " [ 15 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.51        59\n",
      "           1       0.79      0.89      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.66      0.67       200\n",
      "weighted avg       0.74      0.76      0.74       200\n",
      "\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7800\n",
      "Precision: 0.8089\n",
      "Recall: 0.9007\n",
      "F1-score: 0.8523\n",
      "AUC-ROC: 0.6961\n",
      "[[ 29  30]\n",
      " [ 14 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.49      0.57        59\n",
      "           1       0.81      0.90      0.85       141\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.74      0.70      0.71       200\n",
      "weighted avg       0.77      0.78      0.77       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.7800\n",
      "Precision: 0.7870\n",
      "Recall: 0.9433\n",
      "F1-score: 0.8581\n",
      "AUC-ROC: 0.6665\n",
      "[[ 23  36]\n",
      " [  8 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.39      0.51        59\n",
      "           1       0.79      0.94      0.86       141\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.76      0.67      0.68       200\n",
      "weighted avg       0.77      0.78      0.76       200\n",
      "\n",
      "\n",
      "\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.7250\n",
      "Precision: 0.7688\n",
      "Recall: 0.8723\n",
      "F1-score: 0.8173\n",
      "AUC-ROC: 0.6226\n",
      "[[ 22  37]\n",
      " [ 18 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.37      0.44        59\n",
      "           1       0.77      0.87      0.82       141\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.66      0.62      0.63       200\n",
      "weighted avg       0.70      0.72      0.71       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6650\n",
      "Precision: 0.7681\n",
      "Recall: 0.7518\n",
      "F1-score: 0.7599\n",
      "AUC-ROC: 0.6047\n",
      "[[ 27  32]\n",
      " [ 35 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45        59\n",
      "           1       0.77      0.75      0.76       141\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7738\n",
      "Recall: 0.9220\n",
      "F1-score: 0.8414\n",
      "AUC-ROC: 0.6390\n",
      "[[ 21  38]\n",
      " [ 11 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.36      0.46        59\n",
      "           1       0.77      0.92      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.72      0.64      0.65       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.7300\n",
      "Precision: 0.7771\n",
      "Recall: 0.8652\n",
      "F1-score: 0.8188\n",
      "AUC-ROC: 0.6360\n",
      "[[ 24  35]\n",
      " [ 19 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.47        59\n",
      "           1       0.78      0.87      0.82       141\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.67      0.64      0.64       200\n",
      "weighted avg       0.71      0.73      0.72       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.7150\n",
      "Precision: 0.7763\n",
      "Recall: 0.8369\n",
      "F1-score: 0.8055\n",
      "AUC-ROC: 0.6303\n",
      "[[ 25  34]\n",
      " [ 23 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.47        59\n",
      "           1       0.78      0.84      0.81       141\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.65      0.63      0.64       200\n",
      "weighted avg       0.70      0.71      0.71       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Bernoulli Naive Bayes\n",
      "Accuracy: 0.7150\n",
      "Precision: 0.7500\n",
      "Recall: 0.8936\n",
      "F1-score: 0.8155\n",
      "AUC-ROC: 0.5909\n",
      "[[ 17  42]\n",
      " [ 15 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37        59\n",
      "           1       0.75      0.89      0.82       141\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.64      0.59      0.59       200\n",
      "weighted avg       0.69      0.71      0.69       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Linear Discriminant Analysis\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7805\n",
      "Recall: 0.9078\n",
      "F1-score: 0.8393\n",
      "AUC-ROC: 0.6488\n",
      "[[ 23  36]\n",
      " [ 13 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.39      0.48        59\n",
      "           1       0.78      0.91      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.65      0.66       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Quadratic Discriminant Analysis\n",
      "Accuracy: 0.7700\n",
      "Precision: 0.8105\n",
      "Recall: 0.8794\n",
      "F1-score: 0.8435\n",
      "AUC-ROC: 0.6940\n",
      "[[ 30  29]\n",
      " [ 17 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57        59\n",
      "           1       0.81      0.88      0.84       141\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.72      0.69      0.70       200\n",
      "weighted avg       0.76      0.77      0.76       200\n",
      "\n",
      "\n",
      "\n",
      "Model: Extra Trees\n",
      "Accuracy: 0.7100\n",
      "Precision: 0.7712\n",
      "Recall: 0.8369\n",
      "F1-score: 0.8027\n",
      "AUC-ROC: 0.6218\n",
      "[[ 24  35]\n",
      " [ 23 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.41      0.45        59\n",
      "           1       0.77      0.84      0.80       141\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.64      0.62      0.63       200\n",
      "weighted avg       0.69      0.71      0.70       200\n",
      "\n",
      "\n",
      "\n",
      "Best model saved: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if auc_roc > best_score:\n",
    "        best_score = auc_roc\n",
    "        best_model = model\n",
    "\n",
    "# Save the best-performing model using pickle\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best model saved: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7561 (0.0399)\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7771\n",
      "Recall: 0.9149\n",
      "F1-score: 0.8404\n",
      "AUC-ROC: 0.6439\n",
      "[[ 22  37]\n",
      " [ 12 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47        59\n",
      "           1       0.78      0.91      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.64      0.66       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "Random Forest: 0.7425 (0.0534)\n",
      "Model: Random Forest\n",
      "Accuracy: 0.7500\n",
      "Precision: 0.7791\n",
      "Recall: 0.9007\n",
      "F1-score: 0.8355\n",
      "AUC-ROC: 0.6453\n",
      "[[ 23  36]\n",
      " [ 14 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.39      0.48        59\n",
      "           1       0.78      0.90      0.84       141\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.70      0.65      0.66       200\n",
      "weighted avg       0.73      0.75      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "XGBoost: nan (nan)\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7800\n",
      "Precision: 0.8089\n",
      "Recall: 0.9007\n",
      "F1-score: 0.8523\n",
      "AUC-ROC: 0.6961\n",
      "[[ 29  30]\n",
      " [ 14 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.49      0.57        59\n",
      "           1       0.81      0.90      0.85       141\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.74      0.70      0.71       200\n",
      "weighted avg       0.77      0.78      0.77       200\n",
      "\n",
      "\n",
      "\n",
      "Gradient Boosting: 0.7327 (0.0476)\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.7800\n",
      "Precision: 0.7870\n",
      "Recall: 0.9433\n",
      "F1-score: 0.8581\n",
      "AUC-ROC: 0.6665\n",
      "[[ 23  36]\n",
      " [  8 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.39      0.51        59\n",
      "           1       0.79      0.94      0.86       141\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.76      0.67      0.68       200\n",
      "weighted avg       0.77      0.78      0.76       200\n",
      "\n",
      "\n",
      "\n",
      "AdaBoost: 0.7312 (0.0399)\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.7250\n",
      "Precision: 0.7688\n",
      "Recall: 0.8723\n",
      "F1-score: 0.8173\n",
      "AUC-ROC: 0.6226\n",
      "[[ 22  37]\n",
      " [ 18 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.37      0.44        59\n",
      "           1       0.77      0.87      0.82       141\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.66      0.62      0.63       200\n",
      "weighted avg       0.70      0.72      0.71       200\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree: 0.6047 (0.0442)\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6700\n",
      "Precision: 0.7660\n",
      "Recall: 0.7660\n",
      "F1-score: 0.7660\n",
      "AUC-ROC: 0.6033\n",
      "[[ 26  33]\n",
      " [ 33 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44        59\n",
      "           1       0.77      0.77      0.77       141\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "\n",
      "\n",
      "Support Vector Machine: 0.7455 (0.0382)\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7738\n",
      "Recall: 0.9220\n",
      "F1-score: 0.8414\n",
      "AUC-ROC: 0.6390\n",
      "[[ 21  38]\n",
      " [ 11 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.36      0.46        59\n",
      "           1       0.77      0.92      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.72      0.64      0.65       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "K-Nearest Neighbors: 0.6902 (0.0405)\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.7300\n",
      "Precision: 0.7771\n",
      "Recall: 0.8652\n",
      "F1-score: 0.8188\n",
      "AUC-ROC: 0.6360\n",
      "[[ 24  35]\n",
      " [ 19 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.47        59\n",
      "           1       0.78      0.87      0.82       141\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.67      0.64      0.64       200\n",
      "weighted avg       0.71      0.73      0.72       200\n",
      "\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes: 0.7481 (0.0393)\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.7150\n",
      "Precision: 0.7763\n",
      "Recall: 0.8369\n",
      "F1-score: 0.8055\n",
      "AUC-ROC: 0.6303\n",
      "[[ 25  34]\n",
      " [ 23 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.47        59\n",
      "           1       0.78      0.84      0.81       141\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.65      0.63      0.64       200\n",
      "weighted avg       0.70      0.71      0.71       200\n",
      "\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes: 0.7023 (0.0351)\n",
      "Model: Bernoulli Naive Bayes\n",
      "Accuracy: 0.7150\n",
      "Precision: 0.7500\n",
      "Recall: 0.8936\n",
      "F1-score: 0.8155\n",
      "AUC-ROC: 0.5909\n",
      "[[ 17  42]\n",
      " [ 15 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37        59\n",
      "           1       0.75      0.89      0.82       141\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.64      0.59      0.59       200\n",
      "weighted avg       0.69      0.71      0.69       200\n",
      "\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis: 0.7558 (0.0392)\n",
      "Model: Linear Discriminant Analysis\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.7805\n",
      "Recall: 0.9078\n",
      "F1-score: 0.8393\n",
      "AUC-ROC: 0.6488\n",
      "[[ 23  36]\n",
      " [ 13 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.39      0.48        59\n",
      "           1       0.78      0.91      0.84       141\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.65      0.66       200\n",
      "weighted avg       0.74      0.76      0.73       200\n",
      "\n",
      "\n",
      "\n",
      "Quadratic Discriminant Analysis: 0.7328 (0.0379)\n",
      "Model: Quadratic Discriminant Analysis\n",
      "Accuracy: 0.7700\n",
      "Precision: 0.8105\n",
      "Recall: 0.8794\n",
      "F1-score: 0.8435\n",
      "AUC-ROC: 0.6940\n",
      "[[ 30  29]\n",
      " [ 17 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57        59\n",
      "           1       0.81      0.88      0.84       141\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.72      0.69      0.70       200\n",
      "weighted avg       0.76      0.77      0.76       200\n",
      "\n",
      "\n",
      "\n",
      "Extra Trees: 0.7131 (0.0580)\n",
      "Model: Extra Trees\n",
      "Accuracy: 0.7350\n",
      "Precision: 0.7857\n",
      "Recall: 0.8582\n",
      "F1-score: 0.8203\n",
      "AUC-ROC: 0.6494\n",
      "[[ 26  33]\n",
      " [ 20 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50        59\n",
      "           1       0.79      0.86      0.82       141\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.68      0.65      0.66       200\n",
      "weighted avg       0.72      0.73      0.72       200\n",
      "\n",
      "\n",
      "\n",
      "Best model saved: XGBClassifierWrapper()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the XGBClassifier wrapper for sklearn compatibility\n",
    "class XGBClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Define the parameters explicitly in the constructor\n",
    "        self.model = XGBClassifier(  **kwargs)\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Fit the XGBClassifier model\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict using the fitted model\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Predict probabilities using the fitted model\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        # Return the accuracy score using the model\n",
    "        return self.model.score(X, y)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifierWrapper(eval_metric='logloss'),  # Using the wrapped XGBClassifier\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_score = 0\n",
    "for name, model in models.items():\n",
    "    kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    print(f\"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if auc_roc > best_score:\n",
    "        best_score = auc_roc\n",
    "        best_model = model\n",
    "\n",
    "# Save the best-performing model using pickle\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best model saved: {best_model}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databeezhackvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
